{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost time serien forecosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# hide warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sktime.utils.plotting import plot_series, plot_lags, plot_correlations\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sktime.split import temporal_train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import category_encoders as ce\n",
    "from statsmodels.tsa.deterministic import DeterministicProcess\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "import h2o\n",
    "from h2o.estimators import H2OTargetEncoderEstimator\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Matplotlib defaults\n",
    "#print(plt.style.available)\n",
    "#plt.style.use(\"seaborn-v0_8-whitegrid'\")\n",
    "\n",
    "plt.rc(\n",
    "    \"figure\",\n",
    "    autolayout=True,\n",
    "    figsize=(11, 4),\n",
    "    titlesize=18,\n",
    "    titleweight='bold',\n",
    ")\n",
    "\n",
    "plt.rc(\n",
    "    \"axes\",\n",
    "    labelweight=\"bold\",\n",
    "    labelsize=\"large\",\n",
    "    titleweight=\"bold\",\n",
    "    titlesize=16,\n",
    "    titlepad=10,\n",
    ")\n",
    "\n",
    "plot_params = dict(\n",
    "    color=\"0.75\",\n",
    "    style=\".-\",\n",
    "    markeredgecolor=\"0.25\",\n",
    "    markerfacecolor=\"0.25\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays_url = '../data//holidays_events.csv'\n",
    "oil_url = '../data//oil.csv'\n",
    "stores_url = '../data/stores.csv'\n",
    "test_url = '../data/test.csv'\n",
    "train_url = '../data//train.csv'\n",
    "transactions_url = '../data/transactions.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data to data frame\n",
    "df_holidays = pd.read_csv(holidays_url)\n",
    "df_oil = pd.read_csv(oil_url)\n",
    "df_stores = pd.read_csv(stores_url)\n",
    "df_test = pd.read_csv(test_url)\n",
    "df_train = pd.read_csv(train_url)\n",
    "df_transactions = pd.read_csv(transactions_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'date' to datetime\n",
    "df_holidays['date'] = pd.to_datetime(df_holidays['date'])\n",
    "df_oil['date'] = pd.to_datetime(df_oil['date'])\n",
    "df_train['date'] = pd.to_datetime(df_train['date'])\n",
    "df_test['date'] = pd.to_datetime(df_test['date'])\n",
    "df_transactions['date'] = pd.to_datetime(df_transactions['date']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling missing oil prices\n",
    "full_date_range = pd.date_range(start=df_oil['date'].min(), end=df_oil['date'].max())\n",
    "full_date_df = pd.DataFrame({'date': full_date_range})\n",
    "df_oil = pd.merge(full_date_df, df_oil, on='date', how='left')\n",
    "df_oil['dcoilwtico'] = df_oil['dcoilwtico'].interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge with oil price\n",
    "df_train_fe = pd.merge(left= df_train, right= df_oil, how= 'left', on= 'date')\n",
    "#merge with store info\n",
    "df_train_fe = pd.merge(left= df_train_fe, right= df_stores, how= 'left', on= 'store_nbr')\n",
    "\n",
    "#merge with holiday data\n",
    "\n",
    "# Step 1: Split df_holidays based on the locale type\n",
    "national_holidays = df_holidays[df_holidays['locale'] == 'National']\n",
    "regional_holidays = df_holidays[df_holidays['locale'] == 'Regional']\n",
    "local_holidays = df_holidays[df_holidays['locale'] == 'Local']\n",
    "\n",
    "# Step 2: Merge each type separately\n",
    "\n",
    "# 2.1 National Holidays: Merge only on date\n",
    "df_merged_national = pd.merge(df_train_fe, national_holidays, on='date', how='left')\n",
    "\n",
    "# 2.2 Regional Holidays: Merge on date and state (locale_name corresponds to state in df_train_fe)\n",
    "df_merged_regional = pd.merge(\n",
    "    df_train_fe, \n",
    "    regional_holidays, \n",
    "    left_on=['date', 'state'], \n",
    "    right_on=['date', 'locale_name'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 2.3 Local Holidays: Merge on date and city (locale_name corresponds to city in df_train_fe)\n",
    "df_merged_local = pd.merge(\n",
    "    df_train_fe, \n",
    "    local_holidays, \n",
    "    left_on=['date', 'city'], \n",
    "    right_on=['date', 'locale_name'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Step 3: Combine the results\n",
    "\n",
    "# Start with National holidays\n",
    "df_combined = df_merged_national.copy()\n",
    "\n",
    "# Add columns from Regional merge, without duplicating\n",
    "df_combined = df_combined.combine_first(df_merged_regional)\n",
    "\n",
    "# Add columns from Local merge, without duplicating\n",
    "df_combined = df_combined.combine_first(df_merged_local)\n",
    "\n",
    "# Clean-up step (optional): You can drop unnecessary columns or fill NaN values\n",
    "# Drop locale_name columns if you want\n",
    "df_combined = df_combined.drop(['locale_name'], axis=1, errors='ignore')\n",
    "\n",
    "# Fill NaN values in the description or type columns as needed\n",
    "df_combined['description'] = df_combined['description'].fillna('No Holiday')\n",
    "\n",
    "#Create is_holiday column\n",
    "df_combined['is_holiday'] = df_combined['type_y'].notna().astype(int)\n",
    "\n",
    "# Show the combined dataframe\n",
    "df_train_fe = df_combined.copy()\n",
    "\n",
    "#rename columns\n",
    "df_train_fe = df_train_fe.rename(columns= {'type_x': 'type_store',\n",
    "                                           'cluster': 'cluster_store',\n",
    "                                           'dcoilwtico': 'oil_price',\n",
    "                                           'type_y': 'type_holiday',\n",
    "                                           'locale': 'scale_holiday',\n",
    "                                           'description': 'description_holiday',\n",
    "                                           'transferred': 'transferred_holiday'\n",
    "                                           })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>oil_price</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type_store</th>\n",
       "      <th>cluster_store</th>\n",
       "      <th>type_holiday</th>\n",
       "      <th>scale_holiday</th>\n",
       "      <th>description_holiday</th>\n",
       "      <th>transferred_holiday</th>\n",
       "      <th>is_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>National</td>\n",
       "      <td>Primer dia del ano</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>National</td>\n",
       "      <td>Primer dia del ano</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>National</td>\n",
       "      <td>Primer dia del ano</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>National</td>\n",
       "      <td>Primer dia del ano</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>National</td>\n",
       "      <td>Primer dia del ano</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       date  store_nbr      family  sales  onpromotion  oil_price   city   \n",
       "0   0 2013-01-01          1  AUTOMOTIVE    0.0            0        NaN  Quito  \\\n",
       "1   1 2013-01-01          1   BABY CARE    0.0            0        NaN  Quito   \n",
       "2   2 2013-01-01          1      BEAUTY    0.0            0        NaN  Quito   \n",
       "3   3 2013-01-01          1   BEVERAGES    0.0            0        NaN  Quito   \n",
       "4   4 2013-01-01          1       BOOKS    0.0            0        NaN  Quito   \n",
       "\n",
       "       state type_store  cluster_store type_holiday scale_holiday   \n",
       "0  Pichincha          D             13      Holiday      National  \\\n",
       "1  Pichincha          D             13      Holiday      National   \n",
       "2  Pichincha          D             13      Holiday      National   \n",
       "3  Pichincha          D             13      Holiday      National   \n",
       "4  Pichincha          D             13      Holiday      National   \n",
       "\n",
       "  description_holiday transferred_holiday  is_holiday  \n",
       "0  Primer dia del ano               False           1  \n",
       "1  Primer dia del ano               False           1  \n",
       "2  Primer dia del ano               False           1  \n",
       "3  Primer dia del ano               False           1  \n",
       "4  Primer dia del ano               False           1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_fe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datetime features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract useful features from the datetime column\n",
    "df_train_fe['year'] = df_train_fe['date'].dt.year\n",
    "df_train_fe['month'] = df_train_fe['date'].dt.month\n",
    "df_train_fe['weekofyear'] = df_train_fe['date'].dt.isocalendar().week\n",
    "df_train_fe['dayofyear'] = df_train_fe['date'].dt.dayofyear\n",
    "df_train_fe['day'] = df_train_fe['date'].dt.day\n",
    "df_train_fe['day_of_week'] = df_train_fe['date'].dt.dayofweek\n",
    "df_train_fe['is_weekend'] = (df_train_fe['day_of_week'] >= 5).astype(int)\n",
    "df_train_fe['quarter'] = df_train_fe['date'].dt.quarter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>oil_price</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type_store</th>\n",
       "      <th>...</th>\n",
       "      <th>transferred_holiday</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       date  store_nbr      family  sales  onpromotion  oil_price   city   \n",
       "0   0 2013-01-01          1  AUTOMOTIVE    0.0            0        NaN  Quito  \\\n",
       "1   1 2013-01-01          1   BABY CARE    0.0            0        NaN  Quito   \n",
       "2   2 2013-01-01          1      BEAUTY    0.0            0        NaN  Quito   \n",
       "3   3 2013-01-01          1   BEVERAGES    0.0            0        NaN  Quito   \n",
       "4   4 2013-01-01          1       BOOKS    0.0            0        NaN  Quito   \n",
       "\n",
       "       state type_store  ...  transferred_holiday is_holiday  year month   \n",
       "0  Pichincha          D  ...                False          1  2013     1  \\\n",
       "1  Pichincha          D  ...                False          1  2013     1   \n",
       "2  Pichincha          D  ...                False          1  2013     1   \n",
       "3  Pichincha          D  ...                False          1  2013     1   \n",
       "4  Pichincha          D  ...                False          1  2013     1   \n",
       "\n",
       "  weekofyear  dayofyear  day  day_of_week  is_weekend  quarter  \n",
       "0          1          1    1            1           0        1  \n",
       "1          1          1    1            1           0        1  \n",
       "2          1          1    1            1           0        1  \n",
       "3          1          1    1            1           0        1  \n",
       "4          1          1    1            1           0        1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_fe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lag features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lags(ts, lags):\n",
    "\n",
    "    \"\"\"Function to create lag features\n",
    "\n",
    "    Returns:\n",
    "        df: df with added lag features\n",
    "    \"\"\"\n",
    "    return pd.concat(\n",
    "        {\n",
    "            f'y_lag_{i}': ts.shift(i)\n",
    "            for i in range(1, lags + 1)\n",
    "        },\n",
    "        axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_train = df_train_fe.groupby(['store_nbr','family'])\n",
    "\n",
    "df_combined = []\n",
    "\n",
    "#feature engineering of data frames\n",
    "for (store, family), df in groups_train:\n",
    "    df['store_nbr'] = store\n",
    "    df['family'] = family\n",
    "\n",
    "    df_lags = make_lags(df['sales'], 39)\n",
    "    df = pd.concat([df, df_lags], axis= 1)\n",
    "\n",
    "    df_combined.append(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rolling features (moving averages)\n",
    "\n",
    "for df in df_combined:\n",
    "\n",
    "    df['rolling_7_sales'] = df['sales'].rolling(window=7).mean()\n",
    "    df['rolling_14_sales'] = df['sales'].rolling(window=14).mean()\n",
    "    df['rolling_30_sales'] = df['sales'].rolling(window=30).mean()\n",
    "\n",
    "#Shift by one to avoid leakage\n",
    "    df['rolling_7_sales'] = df['rolling_7_sales'].shift(1)\n",
    "    df['rolling_14_sales'] = df['rolling_14_sales'].shift(1)\n",
    "    df['rolling_30_sales'] = df['rolling_30_sales'].shift(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_fe = pd.concat(df_combined, axis= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'date', 'store_nbr', 'family', 'sales', 'onpromotion',\n",
       "       'oil_price', 'city', 'state', 'type_store', 'cluster_store',\n",
       "       'type_holiday', 'scale_holiday', 'description_holiday',\n",
       "       'transferred_holiday', 'is_holiday', 'year', 'month', 'weekofyear',\n",
       "       'dayofyear', 'day', 'day_of_week', 'is_weekend', 'quarter', 'y_lag_1',\n",
       "       'y_lag_2', 'y_lag_3', 'y_lag_4', 'y_lag_5', 'y_lag_6', 'y_lag_7',\n",
       "       'y_lag_8', 'y_lag_9', 'y_lag_10', 'y_lag_11', 'y_lag_12', 'y_lag_13',\n",
       "       'y_lag_14', 'y_lag_15', 'y_lag_16', 'y_lag_17', 'y_lag_18', 'y_lag_19',\n",
       "       'y_lag_20', 'y_lag_21', 'y_lag_22', 'y_lag_23', 'y_lag_24', 'y_lag_25',\n",
       "       'y_lag_26', 'y_lag_27', 'y_lag_28', 'y_lag_29', 'y_lag_30', 'y_lag_31',\n",
       "       'y_lag_32', 'y_lag_33', 'y_lag_34', 'y_lag_35', 'y_lag_36', 'y_lag_37',\n",
       "       'y_lag_38', 'y_lag_39', 'rolling_7_sales', 'rolling_14_sales',\n",
       "       'rolling_30_sales'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_fe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_drop = ['city', 'state', 'type_holiday', 'scale_holiday', 'description_holiday', 'transferred_holiday']\n",
    "\n",
    "df_train_fe.drop(columns= columns_drop, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                      0\n",
       "date                    0\n",
       "store_nbr               0\n",
       "family                  0\n",
       "sales                   0\n",
       "onpromotion             0\n",
       "oil_price            1782\n",
       "type_store              0\n",
       "cluster_store           0\n",
       "is_holiday              0\n",
       "year                    0\n",
       "month                   0\n",
       "weekofyear              0\n",
       "dayofyear               0\n",
       "day                     0\n",
       "day_of_week             0\n",
       "is_weekend              0\n",
       "quarter                 0\n",
       "y_lag_1              1782\n",
       "y_lag_2              3564\n",
       "y_lag_3              5346\n",
       "y_lag_4              7128\n",
       "y_lag_5              8910\n",
       "y_lag_6             10692\n",
       "y_lag_7             12474\n",
       "y_lag_8             14256\n",
       "y_lag_9             16038\n",
       "y_lag_10            17820\n",
       "y_lag_11            19602\n",
       "y_lag_12            21384\n",
       "y_lag_13            23166\n",
       "y_lag_14            24948\n",
       "y_lag_15            26730\n",
       "y_lag_16            28512\n",
       "y_lag_17            30294\n",
       "y_lag_18            32076\n",
       "y_lag_19            33858\n",
       "y_lag_20            35640\n",
       "y_lag_21            37422\n",
       "y_lag_22            39204\n",
       "y_lag_23            40986\n",
       "y_lag_24            42768\n",
       "y_lag_25            44550\n",
       "y_lag_26            46332\n",
       "y_lag_27            48114\n",
       "y_lag_28            49896\n",
       "y_lag_29            51678\n",
       "y_lag_30            53460\n",
       "y_lag_31            55242\n",
       "y_lag_32            57024\n",
       "y_lag_33            58806\n",
       "y_lag_34            60588\n",
       "y_lag_35            62370\n",
       "y_lag_36            64152\n",
       "y_lag_37            65934\n",
       "y_lag_38            67716\n",
       "y_lag_39            69498\n",
       "rolling_7_sales     12474\n",
       "rolling_14_sales    24948\n",
       "rolling_30_sales    53460\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_fe.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_fe = df_train_fe.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_fe = df_train_fe.sort_values('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['store_nbr', 'family', 'type_store', 'cluster_store']\n",
    "\n",
    "# Convert columns to categorical\n",
    "df_train_fe[cat_columns] = df_train_fe[cat_columns].apply(lambda col: col.astype('category'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(df_train_fe, cat_columns, encoder):\n",
    "\n",
    "    for cat in cat_columns:\n",
    "\n",
    "        if encoder == 'label':\n",
    "\n",
    "            le = LabelEncoder()\n",
    "\n",
    "            for cat in cat_columns:\n",
    "                df_train_fe[cat] = le.fit_transform(df_train_fe[cat])\n",
    "\n",
    "\n",
    "        elif encoder == 'one':\n",
    "\n",
    "            for cat in cat_columns:\n",
    "                df_train_fe = pd.get_dummies(df_train_fe, columns=[cat])\n",
    "\n",
    "\n",
    "        elif encoder == 'target':\n",
    "\n",
    "            # Train a TE model\n",
    "            encoder_te = H2OTargetEncoderEstimator(data_leakage_handling=\"leave_one_out\",\n",
    "                                                    blending=True,\n",
    "                                                    inflection_point=3,\n",
    "                                                    smoothing=10,\n",
    "                                                    noise=0.15     # In general, the less data you have the more regularization you need\n",
    "                                                )\n",
    "\n",
    "            encoder_te.train(x= cat_columns,\n",
    "                            y= df_train_fe['sales'],\n",
    "                            training_frame= df_train_fe)\n",
    "\n",
    "            # New target encoded train and test sets\n",
    "            df_train_fe = encoder_te.transform(frame= df_train_fe, as_training=True) #True for training data, False for test data\n",
    "                \n",
    "    return df_train_fe\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['store_nbr'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_train_fe_test \u001b[38;5;241m=\u001b[39m \u001b[43mencoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train_fe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mone\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 16\u001b[0m, in \u001b[0;36mencoding\u001b[0;34m(df_train_fe, cat_columns, encoder)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m encoder \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mone\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cat \u001b[38;5;129;01min\u001b[39;00m cat_columns:\n\u001b[0;32m---> 16\u001b[0m         df_train_fe \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dummies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train_fe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m encoder \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# Train a TE model\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     encoder_te \u001b[38;5;241m=\u001b[39m H2OTargetEncoderEstimator(data_leakage_handling\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleave_one_out\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     23\u001b[0m                                             blending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     24\u001b[0m                                             inflection_point\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     25\u001b[0m                                             smoothing\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     26\u001b[0m                                             noise\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.15\u001b[39m     \u001b[38;5;66;03m# In general, the less data you have the more regularization you need\u001b[39;00m\n\u001b[1;32m     27\u001b[0m                                         )\n",
      "File \u001b[0;32m~/Desktop/neuefische_Bootcamp/da-youtube_EDA/.venv/lib/python3.11/site-packages/pandas/core/reshape/encoding.py:158\u001b[0m, in \u001b[0;36mget_dummies\u001b[0;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput must be a list-like for parameter `columns`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     data_to_encode \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# validate prefixes and separator to avoid silently dropping cols\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_len\u001b[39m(item, name):\n",
      "File \u001b[0;32m~/Desktop/neuefische_Bootcamp/da-youtube_EDA/.venv/lib/python3.11/site-packages/pandas/core/frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/neuefische_Bootcamp/da-youtube_EDA/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:5876\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5873\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5874\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5876\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5878\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5880\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/neuefische_Bootcamp/da-youtube_EDA/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:5935\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   5934\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 5935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5937\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   5938\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['store_nbr'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "df_train_fe_test = encoding(df_train_fe, cat_columns, encoder= 'one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>oil_price</th>\n",
       "      <th>type_store</th>\n",
       "      <th>cluster_store</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>...</th>\n",
       "      <th>y_lag_33</th>\n",
       "      <th>y_lag_34</th>\n",
       "      <th>y_lag_35</th>\n",
       "      <th>y_lag_36</th>\n",
       "      <th>y_lag_37</th>\n",
       "      <th>y_lag_38</th>\n",
       "      <th>y_lag_39</th>\n",
       "      <th>rolling_7_sales</th>\n",
       "      <th>rolling_14_sales</th>\n",
       "      <th>rolling_30_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69498</th>\n",
       "      <td>69498</td>\n",
       "      <td>2013-02-09</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0</td>\n",
       "      <td>96.143333</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>2.071429</td>\n",
       "      <td>2.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69499</th>\n",
       "      <td>69499</td>\n",
       "      <td>2013-02-09</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>96.143333</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69500</th>\n",
       "      <td>69500</td>\n",
       "      <td>2013-02-09</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0</td>\n",
       "      <td>96.143333</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69501</th>\n",
       "      <td>69501</td>\n",
       "      <td>2013-02-09</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>783.000</td>\n",
       "      <td>0</td>\n",
       "      <td>96.143333</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1158.000</td>\n",
       "      <td>407.000</td>\n",
       "      <td>1160.000</td>\n",
       "      <td>953.000</td>\n",
       "      <td>919.000</td>\n",
       "      <td>1091.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>811.714286</td>\n",
       "      <td>830.642857</td>\n",
       "      <td>916.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69502</th>\n",
       "      <td>69502</td>\n",
       "      <td>2013-02-09</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>96.143333</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008011</th>\n",
       "      <td>3000883</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>POULTRY</td>\n",
       "      <td>438.133</td>\n",
       "      <td>0</td>\n",
       "      <td>47.570000</td>\n",
       "      <td>B</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>317.900</td>\n",
       "      <td>350.776</td>\n",
       "      <td>323.436</td>\n",
       "      <td>464.730</td>\n",
       "      <td>686.079</td>\n",
       "      <td>509.43402</td>\n",
       "      <td>439.091000</td>\n",
       "      <td>369.654711</td>\n",
       "      <td>447.313353</td>\n",
       "      <td>428.532999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008012</th>\n",
       "      <td>3000884</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>PREPARED FOODS</td>\n",
       "      <td>154.553</td>\n",
       "      <td>1</td>\n",
       "      <td>47.570000</td>\n",
       "      <td>B</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>92.945</td>\n",
       "      <td>80.142</td>\n",
       "      <td>103.859</td>\n",
       "      <td>126.990</td>\n",
       "      <td>145.922</td>\n",
       "      <td>145.90399</td>\n",
       "      <td>108.145004</td>\n",
       "      <td>115.663141</td>\n",
       "      <td>113.432428</td>\n",
       "      <td>104.690466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008013</th>\n",
       "      <td>3000885</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>PRODUCE</td>\n",
       "      <td>2419.729</td>\n",
       "      <td>148</td>\n",
       "      <td>47.570000</td>\n",
       "      <td>B</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1252.735</td>\n",
       "      <td>1388.688</td>\n",
       "      <td>2182.856</td>\n",
       "      <td>1603.893</td>\n",
       "      <td>2360.294</td>\n",
       "      <td>1884.58400</td>\n",
       "      <td>1227.892000</td>\n",
       "      <td>1508.710857</td>\n",
       "      <td>1609.729214</td>\n",
       "      <td>1593.872033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008014</th>\n",
       "      <td>3000886</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>SCHOOL AND OFFICE SUPPLIES</td>\n",
       "      <td>121.000</td>\n",
       "      <td>8</td>\n",
       "      <td>47.570000</td>\n",
       "      <td>B</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>151.571429</td>\n",
       "      <td>155.928571</td>\n",
       "      <td>77.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008015</th>\n",
       "      <td>3000887</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>16.000</td>\n",
       "      <td>0</td>\n",
       "      <td>47.570000</td>\n",
       "      <td>B</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.713</td>\n",
       "      <td>13.575</td>\n",
       "      <td>9.441</td>\n",
       "      <td>10.946</td>\n",
       "      <td>16.617</td>\n",
       "      <td>8.67400</td>\n",
       "      <td>23.029000</td>\n",
       "      <td>17.902857</td>\n",
       "      <td>19.238786</td>\n",
       "      <td>17.290067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2938518 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id       date store_nbr                      family     sales   \n",
       "69498      69498 2013-02-09         1                  AUTOMOTIVE     4.000  \\\n",
       "69499      69499 2013-02-09         1                   BABY CARE     0.000   \n",
       "69500      69500 2013-02-09         1                      BEAUTY     4.000   \n",
       "69501      69501 2013-02-09         1                   BEVERAGES   783.000   \n",
       "69502      69502 2013-02-09         1                       BOOKS     0.000   \n",
       "...          ...        ...       ...                         ...       ...   \n",
       "3008011  3000883 2017-08-15         9                     POULTRY   438.133   \n",
       "3008012  3000884 2017-08-15         9              PREPARED FOODS   154.553   \n",
       "3008013  3000885 2017-08-15         9                     PRODUCE  2419.729   \n",
       "3008014  3000886 2017-08-15         9  SCHOOL AND OFFICE SUPPLIES   121.000   \n",
       "3008015  3000887 2017-08-15         9                     SEAFOOD    16.000   \n",
       "\n",
       "         onpromotion  oil_price type_store cluster_store  is_holiday  ...   \n",
       "69498              0  96.143333          D            13           0  ...  \\\n",
       "69499              0  96.143333          D            13           0  ...   \n",
       "69500              0  96.143333          D            13           0  ...   \n",
       "69501              0  96.143333          D            13           0  ...   \n",
       "69502              0  96.143333          D            13           0  ...   \n",
       "...              ...        ...        ...           ...         ...  ...   \n",
       "3008011            0  47.570000          B             6           0  ...   \n",
       "3008012            1  47.570000          B             6           0  ...   \n",
       "3008013          148  47.570000          B             6           0  ...   \n",
       "3008014            8  47.570000          B             6           0  ...   \n",
       "3008015            0  47.570000          B             6           0  ...   \n",
       "\n",
       "         y_lag_33  y_lag_34  y_lag_35  y_lag_36  y_lag_37    y_lag_38   \n",
       "69498       0.000     2.000     5.000     3.000     3.000     2.00000  \\\n",
       "69499       0.000     0.000     0.000     0.000     0.000     0.00000   \n",
       "69500       1.000     0.000     3.000     3.000     0.000     2.00000   \n",
       "69501    1158.000   407.000  1160.000   953.000   919.000  1091.00000   \n",
       "69502       0.000     0.000     0.000     0.000     0.000     0.00000   \n",
       "...           ...       ...       ...       ...       ...         ...   \n",
       "3008011   317.900   350.776   323.436   464.730   686.079   509.43402   \n",
       "3008012    92.945    80.142   103.859   126.990   145.922   145.90399   \n",
       "3008013  1252.735  1388.688  2182.856  1603.893  2360.294  1884.58400   \n",
       "3008014     5.000     1.000     3.000     2.000     2.000     1.00000   \n",
       "3008015    17.713    13.575     9.441    10.946    16.617     8.67400   \n",
       "\n",
       "            y_lag_39  rolling_7_sales  rolling_14_sales  rolling_30_sales  \n",
       "69498       0.000000         1.285714          2.071429          2.033333  \n",
       "69499       0.000000         0.000000          0.000000          0.000000  \n",
       "69500       0.000000         2.285714          1.785714          1.600000  \n",
       "69501       0.000000       811.714286        830.642857        916.566667  \n",
       "69502       0.000000         0.000000          0.000000          0.000000  \n",
       "...              ...              ...               ...               ...  \n",
       "3008011   439.091000       369.654711        447.313353        428.532999  \n",
       "3008012   108.145004       115.663141        113.432428        104.690466  \n",
       "3008013  1227.892000      1508.710857       1609.729214       1593.872033  \n",
       "3008014     2.000000       151.571429        155.928571         77.700000  \n",
       "3008015    23.029000        17.902857         19.238786         17.290067  \n",
       "\n",
       "[2938518 rows x 60 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_fe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
