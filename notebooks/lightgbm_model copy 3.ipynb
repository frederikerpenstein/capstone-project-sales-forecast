{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame:\n",
      "   id        date  store_nbr      family  sales  onpromotion\n",
      "0   0  2013-01-01          1  AUTOMOTIVE    0.0            0\n",
      "1   1  2013-01-01          1   BABY CARE    0.0            0\n",
      "2   2  2013-01-01          1      BEAUTY    0.0            0\n",
      "3   3  2013-01-01          1   BEVERAGES    0.0            0\n",
      "4   4  2013-01-01          1       BOOKS    0.0            0 \n",
      "\n",
      "Test DataFrame:\n",
      "        id        date  store_nbr      family  onpromotion\n",
      "0  3000888  2017-08-16          1  AUTOMOTIVE            0\n",
      "1  3000889  2017-08-16          1   BABY CARE            0\n",
      "2  3000890  2017-08-16          1      BEAUTY            2\n",
      "3  3000891  2017-08-16          1   BEVERAGES           20\n",
      "4  3000892  2017-08-16          1       BOOKS            0 \n",
      "\n",
      "Stores DataFrame:\n",
      "   store_nbr           city                           state type  cluster\n",
      "0          1          Quito                       Pichincha    D       13\n",
      "1          2          Quito                       Pichincha    D       13\n",
      "2          3          Quito                       Pichincha    D        8\n",
      "3          4          Quito                       Pichincha    D        9\n",
      "4          5  Santo Domingo  Santo Domingo de los Tsachilas    D        4 \n",
      "\n",
      "Oil DataFrame:\n",
      "         date  dcoilwtico\n",
      "0  2013-01-01         NaN\n",
      "1  2013-01-02       93.14\n",
      "2  2013-01-03       92.97\n",
      "3  2013-01-04       93.12\n",
      "4  2013-01-07       93.20 \n",
      "\n",
      "Holidays DataFrame:\n",
      "         date     type    locale locale_name                    description   \n",
      "0  2012-03-02  Holiday     Local       Manta             Fundacion de Manta  \\\n",
      "1  2012-04-01  Holiday  Regional    Cotopaxi  Provincializacion de Cotopaxi   \n",
      "2  2012-04-12  Holiday     Local      Cuenca            Fundacion de Cuenca   \n",
      "3  2012-04-14  Holiday     Local    Libertad      Cantonizacion de Libertad   \n",
      "4  2012-04-21  Holiday     Local    Riobamba      Cantonizacion de Riobamba   \n",
      "\n",
      "   transferred  \n",
      "0        False  \n",
      "1        False  \n",
      "2        False  \n",
      "3        False  \n",
      "4        False   \n",
      "\n",
      "Transactions DataFrame:\n",
      "         date  store_nbr  transactions\n",
      "0  2013-01-01         25           770\n",
      "1  2013-01-02          1          2111\n",
      "2  2013-01-02          2          2358\n",
      "3  2013-01-02          3          3487\n",
      "4  2013-01-02          4          1922 \n",
      "\n",
      "Missing values in Train Data:\n",
      "id             0\n",
      "date           0\n",
      "store_nbr      0\n",
      "family         0\n",
      "sales          0\n",
      "onpromotion    0\n",
      "dtype: int64 \n",
      "\n",
      "Missing values in Test Data:\n",
      "id             0\n",
      "date           0\n",
      "store_nbr      0\n",
      "family         0\n",
      "onpromotion    0\n",
      "dtype: int64 \n",
      "\n",
      "Missing values in Stores Data:\n",
      "store_nbr    0\n",
      "city         0\n",
      "state        0\n",
      "type         0\n",
      "cluster      0\n",
      "dtype: int64 \n",
      "\n",
      "Missing values in Oil Data:\n",
      "date           0\n",
      "dcoilwtico    43\n",
      "dtype: int64 \n",
      "\n",
      "Missing values in Holidays Data:\n",
      "date           0\n",
      "type           0\n",
      "locale         0\n",
      "locale_name    0\n",
      "description    0\n",
      "transferred    0\n",
      "dtype: int64 \n",
      "\n",
      "Missing values in Transactions Data:\n",
      "date            0\n",
      "store_nbr       0\n",
      "transactions    0\n",
      "dtype: int64 \n",
      "\n",
      "Date columns converted to datetime format.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "df_train = pd.read_csv('../data/train.csv')\n",
    "df_test = pd.read_csv('../data/test.csv')\n",
    "df_stores = pd.read_csv('../data/stores.csv')\n",
    "df_oil = pd.read_csv('../data/oil.csv')\n",
    "df_holidays = pd.read_csv('../data/holidays_events.csv')\n",
    "df_transactions = pd.read_csv('../data/transactions.csv')\n",
    "\n",
    "# Check first few rows of each dataset\n",
    "print(\"Train DataFrame:\")\n",
    "print(df_train.head(), \"\\n\")\n",
    "\n",
    "print(\"Test DataFrame:\")\n",
    "print(df_test.head(), \"\\n\")\n",
    "\n",
    "print(\"Stores DataFrame:\")\n",
    "print(df_stores.head(), \"\\n\")\n",
    "\n",
    "print(\"Oil DataFrame:\")\n",
    "print(df_oil.head(), \"\\n\")\n",
    "\n",
    "print(\"Holidays DataFrame:\")\n",
    "print(df_holidays.head(), \"\\n\")\n",
    "\n",
    "print(\"Transactions DataFrame:\")\n",
    "print(df_transactions.head(), \"\\n\")\n",
    "\n",
    "# Check for missing values in each dataset\n",
    "print(\"Missing values in Train Data:\")\n",
    "print(df_train.isnull().sum(), \"\\n\")\n",
    "\n",
    "print(\"Missing values in Test Data:\")\n",
    "print(df_test.isnull().sum(), \"\\n\")\n",
    "\n",
    "print(\"Missing values in Stores Data:\")\n",
    "print(df_stores.isnull().sum(), \"\\n\")\n",
    "\n",
    "print(\"Missing values in Oil Data:\")\n",
    "print(df_oil.isnull().sum(), \"\\n\")\n",
    "\n",
    "print(\"Missing values in Holidays Data:\")\n",
    "print(df_holidays.isnull().sum(), \"\\n\")\n",
    "\n",
    "print(\"Missing values in Transactions Data:\")\n",
    "print(df_transactions.isnull().sum(), \"\\n\")\n",
    "\n",
    "# Convert date columns to datetime format\n",
    "df_train['date'] = pd.to_datetime(df_train['date'])\n",
    "df_test['date'] = pd.to_datetime(df_test['date'])\n",
    "df_oil['date'] = pd.to_datetime(df_oil['date'])\n",
    "df_holidays['date'] = pd.to_datetime(df_holidays['date'])\n",
    "df_transactions['date'] = pd.to_datetime(df_transactions['date'])\n",
    "\n",
    "# Confirm the conversion of date columns\n",
    "print(\"Date columns converted to datetime format.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Date-Based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame with Date-Based Features:\n",
      "   id       date  store_nbr      family  sales  onpromotion  year  month  day   \n",
      "0   0 2013-01-01          1  AUTOMOTIVE    0.0            0  2013      1    1  \\\n",
      "1   1 2013-01-01          1   BABY CARE    0.0            0  2013      1    1   \n",
      "2   2 2013-01-01          1      BEAUTY    0.0            0  2013      1    1   \n",
      "3   3 2013-01-01          1   BEVERAGES    0.0            0  2013      1    1   \n",
      "4   4 2013-01-01          1       BOOKS    0.0            0  2013      1    1   \n",
      "\n",
      "   day_of_week  week_of_year  day_of_year  \n",
      "0            1             1            1  \n",
      "1            1             1            1  \n",
      "2            1             1            1  \n",
      "3            1             1            1  \n",
      "4            1             1            1  \n",
      "Test DataFrame with Date-Based Features:\n",
      "        id       date  store_nbr      family  onpromotion  year  month  day   \n",
      "0  3000888 2017-08-16          1  AUTOMOTIVE            0  2017      8   16  \\\n",
      "1  3000889 2017-08-16          1   BABY CARE            0  2017      8   16   \n",
      "2  3000890 2017-08-16          1      BEAUTY            2  2017      8   16   \n",
      "3  3000891 2017-08-16          1   BEVERAGES           20  2017      8   16   \n",
      "4  3000892 2017-08-16          1       BOOKS            0  2017      8   16   \n",
      "\n",
      "   day_of_week  week_of_year  day_of_year  \n",
      "0            2            33          228  \n",
      "1            2            33          228  \n",
      "2            2            33          228  \n",
      "3            2            33          228  \n",
      "4            2            33          228  \n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering: Date-based features\n",
    "def create_date_features(df):\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek\n",
    "    df['week_of_year'] = df['date'].dt.isocalendar().week\n",
    "    df['day_of_year'] = df['date'].dt.dayofyear\n",
    "    return df\n",
    "\n",
    "# Apply the function to both train and test datasets\n",
    "df_train = create_date_features(df_train)\n",
    "df_test = create_date_features(df_test)\n",
    "\n",
    "# Confirm the newly created features\n",
    "print(\"Train DataFrame with Date-Based Features:\")\n",
    "print(df_train.head())\n",
    "\n",
    "print(\"Test DataFrame with Date-Based Features:\")\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Create Lag and Rolling Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame with Lag and Rolling Features:\n",
      "   id       date  store_nbr      family  sales  onpromotion  year  month  day   \n",
      "0   0 2013-01-01          1  AUTOMOTIVE    0.0            0  2013      1    1  \\\n",
      "1   1 2013-01-01          1   BABY CARE    0.0            0  2013      1    1   \n",
      "2   2 2013-01-01          1      BEAUTY    0.0            0  2013      1    1   \n",
      "3   3 2013-01-01          1   BEVERAGES    0.0            0  2013      1    1   \n",
      "4   4 2013-01-01          1       BOOKS    0.0            0  2013      1    1   \n",
      "\n",
      "   day_of_week  week_of_year  day_of_year  sales_lag_1  sales_lag_7   \n",
      "0            1             1            1          0.0          0.0  \\\n",
      "1            1             1            1          0.0          0.0   \n",
      "2            1             1            1          0.0          0.0   \n",
      "3            1             1            1          0.0          0.0   \n",
      "4            1             1            1          0.0          0.0   \n",
      "\n",
      "   sales_lag_14  sales_roll_mean_7  sales_roll_std_7  sales_roll_mean_14   \n",
      "0           0.0                0.0               0.0                 0.0  \\\n",
      "1           0.0                0.0               0.0                 0.0   \n",
      "2           0.0                0.0               0.0                 0.0   \n",
      "3           0.0                0.0               0.0                 0.0   \n",
      "4           0.0                0.0               0.0                 0.0   \n",
      "\n",
      "   sales_roll_std_14  \n",
      "0                0.0  \n",
      "1                0.0  \n",
      "2                0.0  \n",
      "3                0.0  \n",
      "4                0.0  \n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering: Lag and rolling features for sales\n",
    "def create_lag_features(df, lags=[1, 7, 14]):\n",
    "    for lag in lags:\n",
    "        df[f'sales_lag_{lag}'] = df.groupby(['store_nbr', 'family'])['sales'].shift(lag)\n",
    "    return df\n",
    "\n",
    "def create_rolling_features(df, windows=[7, 14]):\n",
    "    for window in windows:\n",
    "        df[f'sales_roll_mean_{window}'] = df.groupby(['store_nbr', 'family'])['sales'].transform(lambda x: x.rolling(window).mean())\n",
    "        df[f'sales_roll_std_{window}'] = df.groupby(['store_nbr', 'family'])['sales'].transform(lambda x: x.rolling(window).std())\n",
    "    return df\n",
    "\n",
    "# Apply the lag features to the train dataset\n",
    "df_train = create_lag_features(df_train)\n",
    "df_train = create_rolling_features(df_train)\n",
    "\n",
    "# Since the test set lacks sales history, we can't create lag features for it directly\n",
    "# Fill missing lag feature NaNs with 0\n",
    "df_train.fillna(0, inplace=True)\n",
    "\n",
    "# Confirm the newly created lag and rolling features\n",
    "print(\"Train DataFrame with Lag and Rolling Features:\")\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining missing values in oil data:\n",
      "date          0\n",
      "dcoilwtico    1\n",
      "dtype: int64\n",
      "Remaining missing values in train data after filling:\n",
      "id                    0\n",
      "date                  0\n",
      "store_nbr             0\n",
      "family                0\n",
      "sales                 0\n",
      "onpromotion           0\n",
      "year                  0\n",
      "month                 0\n",
      "day                   0\n",
      "day_of_week           0\n",
      "week_of_year          0\n",
      "day_of_year           0\n",
      "sales_lag_1           0\n",
      "sales_lag_7           0\n",
      "sales_lag_14          0\n",
      "sales_roll_mean_7     0\n",
      "sales_roll_std_7      0\n",
      "sales_roll_mean_14    0\n",
      "sales_roll_std_14     0\n",
      "dtype: int64\n",
      "Remaining missing values in test data after filling:\n",
      "id              0\n",
      "date            0\n",
      "store_nbr       0\n",
      "family          0\n",
      "onpromotion     0\n",
      "year            0\n",
      "month           0\n",
      "day             0\n",
      "day_of_week     0\n",
      "week_of_year    0\n",
      "day_of_year     0\n",
      "dtype: int64\n",
      "Remaining missing values in oil data after backfill:\n",
      "date          0\n",
      "dcoilwtico    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Handle missing oil prices using forward fill\n",
    "df_oil['dcoilwtico'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Check if there are any remaining missing values in oil\n",
    "print(\"Remaining missing values in oil data:\")\n",
    "print(df_oil.isnull().sum())\n",
    "\n",
    "# Ensure lag and rolling feature NaNs in train data are filled (we already did this in the previous step)\n",
    "df_train.fillna(0, inplace=True)\n",
    "\n",
    "# Confirm no missing values in train data\n",
    "print(\"Remaining missing values in train data after filling:\")\n",
    "print(df_train.isnull().sum())\n",
    "\n",
    "# Since the test set doesn't have historical sales, we won't create lag/rolling features for it. \n",
    "# However, ensure there are no other missing values in the test dataset.\n",
    "df_test.fillna(0, inplace=True)\n",
    "print(\"Remaining missing values in test data after filling:\")\n",
    "print(df_test.isnull().sum())\n",
    "\n",
    "# Handle the last remaining missing oil price using backward fill\n",
    "df_oil['dcoilwtico'].fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Verify there are no more missing values in the oil data\n",
    "print(\"Remaining missing values in oil data after backfill:\")\n",
    "print(df_oil.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Holiday Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame with Holiday Features:\n",
      "        date  is_holiday\n",
      "0 2013-01-01           1\n",
      "1 2013-01-01           1\n",
      "2 2013-01-01           1\n",
      "3 2013-01-01           1\n",
      "4 2013-01-01           1\n",
      "Test DataFrame with Holiday Features:\n",
      "        date  is_holiday\n",
      "0 2017-08-16           0\n",
      "1 2017-08-16           0\n",
      "2 2017-08-16           0\n",
      "3 2017-08-16           0\n",
      "4 2017-08-16           0\n"
     ]
    }
   ],
   "source": [
    "# Handle holiday data: create a flag for holidays and calculate days to next holiday\n",
    "def add_holiday_features(df, holidays_df):\n",
    "    # Filter national holidays only\n",
    "    holidays_df = holidays_df[holidays_df['locale'] == 'National'].copy()\n",
    "    \n",
    "    # Merge holidays with the data based on the date\n",
    "    df = df.merge(holidays_df[['date', 'type']], on='date', how='left')\n",
    "    \n",
    "    # Flag if the date is a holiday\n",
    "    df['is_holiday'] = df['type'].notnull().astype(int)\n",
    "    \n",
    "    # Drop the 'type' column after creating the flag\n",
    "    df.drop(columns=['type'], inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply holiday features to train and test datasets\n",
    "df_train = add_holiday_features(df_train, df_holidays)\n",
    "df_test = add_holiday_features(df_test, df_holidays)\n",
    "\n",
    "# Confirm that the holiday feature was added\n",
    "print(\"Train DataFrame with Holiday Features:\")\n",
    "print(df_train[['date', 'is_holiday']].head())\n",
    "\n",
    "print(\"Test DataFrame with Holiday Features:\")\n",
    "print(df_test[['date', 'is_holiday']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Promotion Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame with Promotion Features:\n",
      "        date  store_nbr      family  onpromotion  time_since_last_promo\n",
      "0 2013-01-01          1  AUTOMOTIVE            0                      1\n",
      "1 2013-01-01          1   BABY CARE            0                      1\n",
      "2 2013-01-01          1      BEAUTY            0                      1\n",
      "3 2013-01-01          1   BEVERAGES            0                      1\n",
      "4 2013-01-01          1       BOOKS            0                      1\n"
     ]
    }
   ],
   "source": [
    "# Create time since the last promotion for each store and family\n",
    "def create_time_since_last_promotion(df):\n",
    "    df['promo_not_active'] = (df['onpromotion'] == 0).astype(int)\n",
    "    \n",
    "    # Calculate the cumulative sum of days since the last promotion within each store and product family\n",
    "    df['time_since_last_promo'] = df.groupby(['store_nbr', 'family'])['promo_not_active'].cumsum()\n",
    "    \n",
    "    # Drop the helper column 'promo_not_active'\n",
    "    df.drop(columns=['promo_not_active'], inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply to train dataset (test set doesn't have sales history, so we skip promotions there)\n",
    "df_train = create_time_since_last_promotion(df_train)\n",
    "\n",
    "# Confirm the new promotion-related feature in the train dataset\n",
    "print(\"Train DataFrame with Promotion Features:\")\n",
    "print(df_train[['date', 'store_nbr', 'family', 'onpromotion', 'time_since_last_promo']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  store_nbr  dcoilwtico  transactions\n",
      "0 2013-01-01          1       93.14           0.0\n",
      "1 2013-01-01          1       93.14           0.0\n",
      "2 2013-01-01          1       93.14           0.0\n",
      "3 2013-01-01          1       93.14           0.0\n",
      "4 2013-01-01          1       93.14           0.0\n"
     ]
    }
   ],
   "source": [
    "# Merge oil data into the train dataset based on date\n",
    "df_train = df_train.merge(df_oil[['date', 'dcoilwtico']], on='date', how='left')\n",
    "\n",
    "# Merge transactions data into the train dataset based on date and store number\n",
    "df_train = df_train.merge(df_transactions[['date', 'store_nbr', 'transactions']], on=['date', 'store_nbr'], how='left')\n",
    "\n",
    "# Fill any remaining NaN values in dcoilwtico and transactions\n",
    "df_train['dcoilwtico'].fillna(0, inplace=True)\n",
    "df_train['transactions'].fillna(0, inplace=True)\n",
    "\n",
    "# Verify that the columns are present after merging\n",
    "print(df_train[['date', 'store_nbr', 'dcoilwtico', 'transactions']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1026\n",
      "[LightGBM] [Info] Number of data points in the train set: 501336, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 207.328590\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's rmse: 873.135\n",
      "[200]\tvalid_0's rmse: 868.169\n",
      "[300]\tvalid_0's rmse: 866.702\n",
      "[400]\tvalid_0's rmse: 866.205\n",
      "[500]\tvalid_0's rmse: 866.082\n",
      "[600]\tvalid_0's rmse: 865.975\n",
      "Early stopping, best iteration is:\n",
      "[577]\tvalid_0's rmse: 865.968\n",
      "Validation RMSLE: 3.5074939804486225\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010183 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1180\n",
      "[LightGBM] [Info] Number of data points in the train set: 1002672, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 241.854953\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's rmse: 813.048\n",
      "[200]\tvalid_0's rmse: 771.169\n",
      "[300]\tvalid_0's rmse: 759.517\n",
      "[400]\tvalid_0's rmse: 754.638\n",
      "[500]\tvalid_0's rmse: 752.789\n",
      "[600]\tvalid_0's rmse: 751.432\n",
      "[700]\tvalid_0's rmse: 750.503\n",
      "[800]\tvalid_0's rmse: 749.406\n",
      "[900]\tvalid_0's rmse: 749.417\n",
      "Early stopping, best iteration is:\n",
      "[874]\tvalid_0's rmse: 749.085\n",
      "Validation RMSLE: 2.5313097760693597\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020822 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1227\n",
      "[LightGBM] [Info] Number of data points in the train set: 1504008, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 271.076501\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's rmse: 923.099\n",
      "[200]\tvalid_0's rmse: 847.873\n",
      "[300]\tvalid_0's rmse: 826.064\n",
      "[400]\tvalid_0's rmse: 821.81\n",
      "[500]\tvalid_0's rmse: 819.257\n",
      "[600]\tvalid_0's rmse: 817.588\n",
      "[700]\tvalid_0's rmse: 815.864\n",
      "[800]\tvalid_0's rmse: 815.066\n",
      "[900]\tvalid_0's rmse: 814.529\n",
      "[1000]\tvalid_0's rmse: 813.612\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[970]\tvalid_0's rmse: 813.562\n",
      "Validation RMSLE: 2.00216357259573\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022582 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1272\n",
      "[LightGBM] [Info] Number of data points in the train set: 2005344, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 307.524882\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's rmse: 923.443\n",
      "[200]\tvalid_0's rmse: 831.352\n",
      "[300]\tvalid_0's rmse: 806.88\n",
      "[400]\tvalid_0's rmse: 799.102\n",
      "[500]\tvalid_0's rmse: 795.042\n",
      "[600]\tvalid_0's rmse: 793.686\n",
      "Early stopping, best iteration is:\n",
      "[611]\tvalid_0's rmse: 793.361\n",
      "Validation RMSLE: 1.9037660323187673\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1320\n",
      "[LightGBM] [Info] Number of data points in the train set: 2506680, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 332.722695\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's rmse: 941.99\n",
      "[200]\tvalid_0's rmse: 803.44\n",
      "[300]\tvalid_0's rmse: 755.099\n",
      "[400]\tvalid_0's rmse: 733.329\n",
      "[500]\tvalid_0's rmse: 725.043\n",
      "[600]\tvalid_0's rmse: 721.738\n",
      "[700]\tvalid_0's rmse: 720.318\n",
      "[800]\tvalid_0's rmse: 719.851\n",
      "[900]\tvalid_0's rmse: 718.912\n",
      "[1000]\tvalid_0's rmse: 718.192\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[993]\tvalid_0's rmse: 718.074\n",
      "Validation RMSLE: 1.6379645345948162\n",
      "Average RMSLE across all splits: 2.3165395792054593\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import numpy as np\n",
    "\n",
    "# Define features to be used in the model\n",
    "features = ['onpromotion', 'dcoilwtico', 'transactions', 'year', 'month', 'day', \n",
    "            'day_of_week', 'week_of_year', 'day_of_year', 'time_since_last_promo', \n",
    "            'is_holiday']\n",
    "\n",
    "# Prepare the feature matrix and target variable\n",
    "X = df_train[features]\n",
    "y = df_train['sales']\n",
    "\n",
    "# Use TimeSeriesSplit for cross-validation (to ensure future data isn't used in the past)\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Initialize lists to store evaluation results\n",
    "rmsle_list = []\n",
    "\n",
    "# Loop through each split in the cross-validation\n",
    "for train_index, val_index in tscv.split(X):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    \n",
    "    # Create LightGBM dataset\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val)\n",
    "    \n",
    "    # Set LightGBM parameters\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',  # LightGBM uses RMSE by default, but we calculate RMSLE manually\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate': 0.01,\n",
    "        'num_leaves': 50,\n",
    "        'max_depth': -1,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 1,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    # Use callbacks for early stopping and logging\n",
    "    callbacks = [\n",
    "        lgb.early_stopping(stopping_rounds=50),\n",
    "        lgb.log_evaluation(period=100)\n",
    "    ]\n",
    "    \n",
    "    # Train the model with early stopping callbacks\n",
    "    model = lgb.train(params, train_data, valid_sets=[val_data], num_boost_round=1000, callbacks=callbacks)\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    y_val_pred = np.clip(y_val_pred, a_min=0, a_max=None)  # Ensure no negative predictions\n",
    "    \n",
    "    # Calculate RMSLE on validation set\n",
    "    rmsle = np.sqrt(mean_squared_log_error(y_val, y_val_pred))\n",
    "    rmsle_list.append(rmsle)\n",
    "    \n",
    "    print(f\"Validation RMSLE: {rmsle}\")\n",
    "\n",
    "# Average RMSLE across all splits\n",
    "avg_rmsle = np.mean(rmsle_list)\n",
    "print(f\"Average RMSLE across all splits: {avg_rmsle}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhancing feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame with additional lag and cyclic features:\n",
      "   sales_lag_30  sales_lag_60  sales_lag_90  day_of_week_sin  day_of_week_cos   \n",
      "0           0.0           0.0           0.0         0.781831          0.62349  \\\n",
      "1           0.0           0.0           0.0         0.781831          0.62349   \n",
      "2           0.0           0.0           0.0         0.781831          0.62349   \n",
      "3           0.0           0.0           0.0         0.781831          0.62349   \n",
      "4           0.0           0.0           0.0         0.781831          0.62349   \n",
      "\n",
      "   day_of_year_sin  day_of_year_cos  \n",
      "0         0.017213         0.999852  \n",
      "1         0.017213         0.999852  \n",
      "2         0.017213         0.999852  \n",
      "3         0.017213         0.999852  \n",
      "4         0.017213         0.999852  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1.1 Create additional lag features for 30, 60, and 90 days\n",
    "def create_additional_lag_features(df, lags=[30, 60, 90]):\n",
    "    for lag in lags:\n",
    "        df[f'sales_lag_{lag}'] = df.groupby(['store_nbr', 'family'])['sales'].shift(lag)\n",
    "    return df\n",
    "\n",
    "# 1.2 Create cyclic features for day_of_week and day_of_year\n",
    "def create_cyclic_features(df):\n",
    "    # Cyclic transformation of day_of_week\n",
    "    df['day_of_week_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "    df['day_of_week_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "\n",
    "    # Cyclic transformation of day_of_year\n",
    "    df['day_of_year_sin'] = np.sin(2 * np.pi * df['day_of_year'] / 365)\n",
    "    df['day_of_year_cos'] = np.cos(2 * np.pi * df['day_of_year'] / 365)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the additional lag features to the train dataset\n",
    "df_train = create_additional_lag_features(df_train)\n",
    "\n",
    "# Apply the cyclic transformations to the train dataset\n",
    "df_train = create_cyclic_features(df_train)\n",
    "\n",
    "# Fill missing values resulting from lag feature creation\n",
    "df_train.fillna(0, inplace=True)\n",
    "\n",
    "# Verify that the new features are created\n",
    "print(\"Train DataFrame with additional lag and cyclic features:\")\n",
    "print(df_train[['sales_lag_30', 'sales_lag_60', 'sales_lag_90', 'day_of_week_sin', 'day_of_week_cos', 'day_of_year_sin', 'day_of_year_cos']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update model training with new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007938 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2800\n",
      "[LightGBM] [Info] Number of data points in the train set: 501336, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 207.328590\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's rmse: 413.668\n",
      "[200]\tvalid_0's rmse: 278.017\n",
      "[300]\tvalid_0's rmse: 248.544\n",
      "[400]\tvalid_0's rmse: 242.444\n",
      "[500]\tvalid_0's rmse: 240.872\n",
      "[600]\tvalid_0's rmse: 240.395\n",
      "[700]\tvalid_0's rmse: 240.186\n",
      "[800]\tvalid_0's rmse: 240.045\n",
      "Early stopping, best iteration is:\n",
      "[845]\tvalid_0's rmse: 239.93\n",
      "Validation RMSLE: 0.963898306407128\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014095 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2964\n",
      "[LightGBM] [Info] Number of data points in the train set: 1002672, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 241.854953\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's rmse: 447.276\n",
      "[200]\tvalid_0's rmse: 276.429\n",
      "[300]\tvalid_0's rmse: 239.814\n",
      "[400]\tvalid_0's rmse: 233.913\n",
      "Early stopping, best iteration is:\n",
      "[438]\tvalid_0's rmse: 233.641\n",
      "Validation RMSLE: 1.3417042777233814\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2994\n",
      "[LightGBM] [Info] Number of data points in the train set: 1504008, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 271.076501\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's rmse: 546.807\n",
      "[200]\tvalid_0's rmse: 339.963\n",
      "[300]\tvalid_0's rmse: 285.912\n",
      "[400]\tvalid_0's rmse: 271.522\n",
      "[500]\tvalid_0's rmse: 266.979\n",
      "[600]\tvalid_0's rmse: 265.018\n",
      "[700]\tvalid_0's rmse: 263.996\n",
      "[800]\tvalid_0's rmse: 263.496\n",
      "[900]\tvalid_0's rmse: 263.21\n",
      "[1000]\tvalid_0's rmse: 262.98\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[986]\tvalid_0's rmse: 262.968\n",
      "Validation RMSLE: 0.6960008675047276\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028912 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 2005344, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 307.524882\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's rmse: 601.405\n",
      "[200]\tvalid_0's rmse: 416.06\n",
      "[300]\tvalid_0's rmse: 379.076\n",
      "[400]\tvalid_0's rmse: 372.558\n",
      "[500]\tvalid_0's rmse: 371.102\n",
      "[600]\tvalid_0's rmse: 370.833\n",
      "Early stopping, best iteration is:\n",
      "[586]\tvalid_0's rmse: 370.758\n",
      "Validation RMSLE: 0.8507511368008266\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037108 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3102\n",
      "[LightGBM] [Info] Number of data points in the train set: 2506680, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 332.722695\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's rmse: 614.505\n",
      "[200]\tvalid_0's rmse: 371.002\n",
      "[300]\tvalid_0's rmse: 307.103\n",
      "[400]\tvalid_0's rmse: 289.11\n",
      "[500]\tvalid_0's rmse: 282.584\n",
      "[600]\tvalid_0's rmse: 279.097\n",
      "[700]\tvalid_0's rmse: 277.331\n",
      "[800]\tvalid_0's rmse: 276.406\n",
      "[900]\tvalid_0's rmse: 275.566\n",
      "[1000]\tvalid_0's rmse: 275.033\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 275.033\n",
      "Validation RMSLE: 0.6830880355070704\n",
      "Average RMSLE across all splits: 0.9070885247886269\n"
     ]
    }
   ],
   "source": [
    "# Updated feature list to include additional lag features and cyclic features\n",
    "features = ['onpromotion', 'dcoilwtico', 'transactions', 'year', 'month', 'day', \n",
    "            'day_of_week_sin', 'day_of_week_cos', 'day_of_year_sin', 'day_of_year_cos',\n",
    "            'week_of_year', 'time_since_last_promo', 'is_holiday', \n",
    "            'sales_lag_1', 'sales_lag_7', 'sales_lag_14', 'sales_lag_30', \n",
    "            'sales_lag_60', 'sales_lag_90']\n",
    "\n",
    "# Prepare the feature matrix and target variable\n",
    "X = df_train[features]\n",
    "y = df_train['sales']\n",
    "\n",
    "# Use TimeSeriesSplit for cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Initialize lists to store evaluation results\n",
    "rmsle_list = []\n",
    "\n",
    "# Loop through each split in the cross-validation\n",
    "for train_index, val_index in tscv.split(X):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    \n",
    "    # Create LightGBM dataset\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val)\n",
    "    \n",
    "    # Set LightGBM parameters\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',  # LightGBM uses RMSE by default, but we calculate RMSLE manually\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate': 0.01,\n",
    "        'num_leaves': 50,\n",
    "        'max_depth': -1,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 1,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    # Use callbacks for early stopping and logging\n",
    "    callbacks = [\n",
    "        lgb.early_stopping(stopping_rounds=50),\n",
    "        lgb.log_evaluation(period=100)\n",
    "    ]\n",
    "    \n",
    "    # Train the model with early stopping callbacks\n",
    "    model = lgb.train(params, train_data, valid_sets=[val_data], num_boost_round=1000, callbacks=callbacks)\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    y_val_pred = np.clip(y_val_pred, a_min=0, a_max=None)  # Ensure no negative predictions\n",
    "    \n",
    "    # Calculate RMSLE on validation set\n",
    "    rmsle = np.sqrt(mean_squared_log_error(y_val, y_val_pred))\n",
    "    rmsle_list.append(rmsle)\n",
    "    \n",
    "    print(f\"Validation RMSLE: {rmsle}\")\n",
    "\n",
    "# Average RMSLE across all splits\n",
    "avg_rmsle = np.mean(rmsle_list)\n",
    "print(f\"Average RMSLE across all splits: {avg_rmsle}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning using RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zero or negative sales: 940483\n",
      "Filtered out rows with zero or negative sales. Remaining rows: 2067533\n",
      "Min sales value: 0.122, Max sales value: 124717.0\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.162826 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3090\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378356, number of used features: 19\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Start training from score 504.579952\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.129579 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3154\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 513.053109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.117799 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3090\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378356, number of used features: 19\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Start training from score 504.579952\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.099747 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3149\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.115058 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3149\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.150273 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3154\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 546.084467\n",
      "[LightGBM] [Info] Start training from score 546.084467\n",
      "[LightGBM] [Info] Start training from score 513.053109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037793 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3149\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 546.084467\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.095511 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3154\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 513.053109\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3090\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378356, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 504.579952\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050746 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3149\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 546.084467\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.178768 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3154\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 513.053109\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.197930 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3090\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378356, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 504.579952\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032507 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3149\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 546.084467\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.197614 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3154\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 513.053109\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.366415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3090\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378356, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 504.579952\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.470824 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3149\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 546.084467\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.117524 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3154\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 513.053109\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.159876 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3090\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378356, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 504.579952\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.147299 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3149\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 546.084467\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.102321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3154\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 513.053109\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.080102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3090\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378356, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 504.579952\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.080328 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3149\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 546.084467\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3154\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 513.053109\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.141213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3090\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378356, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 504.579952\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.162112 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3149\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 546.084467\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.235199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3154\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 513.053109\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.163175 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3090\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378356, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 504.579952\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.145647 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3149\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 546.084467\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.191145 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3154\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 513.053109\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.151465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3090\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378356, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 504.579952\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.181933 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3149\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 546.084467\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.134481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3154\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 513.053109\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053264 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3090\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378356, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 504.579952\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079540 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3149\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 546.084467\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.439853 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3154\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 513.053109\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.077901 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3090\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378356, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 504.579952\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.226514 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3149\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 546.084467\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.366691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3154\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 513.053109\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.345665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3090\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378356, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 504.579952\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067534 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3149\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 546.084467\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.205670 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3154\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 513.053109\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.335250 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3090\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378356, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 504.579952\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076774 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3149\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 546.084467\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.157847 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3154\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 513.053109\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.191259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3090\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378356, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 504.579952\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.121363 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3149\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 546.084467\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.140226 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3154\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 513.053109\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.092853 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3090\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378356, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 504.579952\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.193211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3149\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 546.084467\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.171579 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3154\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 513.053109\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.145620 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3090\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378356, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 504.579952\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3149\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 546.084467\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.294585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3154\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 513.053109\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.152963 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3090\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378356, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 504.579952\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.151986 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3149\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 546.084467\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.129316 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3154\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 513.053109\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.188445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3090\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378356, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 504.579952\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.566030 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3149\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 546.084467\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.217301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3154\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378355, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 513.053109\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.134150 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3090\n",
      "[LightGBM] [Info] Number of data points in the train set: 1378356, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 504.579952\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3127\n",
      "[LightGBM] [Info] Number of data points in the train set: 2067533, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 521.239172\n",
      "Best hyperparameters: {'num_leaves': 200, 'min_data_in_leaf': 50, 'learning_rate': 0.01, 'lambda_l2': 0, 'lambda_l1': 0.1, 'feature_fraction': 0.9}\n",
      "Best score (RMSLE): 0.8904283659687198\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_log_error\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings from LightGBM\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Step 1: Check for zero or negative sales values\n",
    "def check_for_zero_negative_sales(df, target_column='sales'):\n",
    "    num_invalid_sales = df[df[target_column] <= 0].shape[0]\n",
    "    if num_invalid_sales > 0:\n",
    "        print(f\"Number of zero or negative sales: {num_invalid_sales}\")\n",
    "    else:\n",
    "        print(\"No zero or negative sales found.\")\n",
    "    return num_invalid_sales\n",
    "\n",
    "# Step 2: Handle zero or negative sales (either filter them or adjust by adding a constant)\n",
    "def handle_zero_negative_sales(df, method='filter'):\n",
    "    if method == 'filter':\n",
    "        # Filter out zero or negative sales\n",
    "        df_filtered = df[df['sales'] > 0]\n",
    "        print(f\"Filtered out rows with zero or negative sales. Remaining rows: {df_filtered.shape[0]}\")\n",
    "        return df_filtered\n",
    "    elif method == 'add_constant':\n",
    "        # Add a small constant to avoid zero or negative sales\n",
    "        df['sales_adjusted'] = df['sales'] + 1\n",
    "        print(\"Added constant of 1 to avoid zero or negative sales.\")\n",
    "        return df\n",
    "\n",
    "# Step 3: Custom RMSLE scorer that clips negative predictions\n",
    "def rmsle_scorer(y_true, y_pred):\n",
    "    # Clip any negative predictions to 0 to avoid errors\n",
    "    y_pred = np.clip(y_pred, a_min=0, a_max=None)\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "\n",
    "# Step 4: Perform Hyperparameter Tuning with RandomizedSearchCV\n",
    "def perform_hyperparameter_tuning(X, y):\n",
    "    # Ensure no zero or negative values in y before proceeding\n",
    "    if (y <= 0).any():\n",
    "        raise ValueError(\"Detected zero or negative values in target variable, can't proceed with RMSLE.\")\n",
    "\n",
    "    # Define the cleaned-up parameter grid for LightGBM\n",
    "    param_grid = {\n",
    "        'num_leaves': [31, 50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'min_data_in_leaf': [20, 30, 50],\n",
    "        'feature_fraction': [0.7, 0.8, 0.9],\n",
    "        'lambda_l1': [0, 0.1, 1],\n",
    "        'lambda_l2': [0, 0.1, 1]\n",
    "    }\n",
    "\n",
    "    # Initialize LightGBM regressor\n",
    "    lgbm = lgb.LGBMRegressor(objective='regression', boosting_type='gbdt', random_state=42, n_estimators=1000)\n",
    "\n",
    "    # Custom RMSLE scorer with clipping\n",
    "    rmsle = make_scorer(rmsle_scorer, greater_is_better=False)\n",
    "\n",
    "    # Set up RandomizedSearchCV\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=lgbm,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=20,\n",
    "        scoring=rmsle,  # Use custom RMSLE scorer\n",
    "        cv=3,  # 3-fold cross-validation\n",
    "        verbose=1,  # Set verbosity to 1 for progress updates\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Perform the random search on the filtered training data\n",
    "    random_search.fit(X, y)\n",
    "\n",
    "    # Output the best parameters and the corresponding RMSLE score\n",
    "    print(\"Best hyperparameters:\", random_search.best_params_)\n",
    "    print(\"Best score (RMSLE):\", np.sqrt(-random_search.best_score_))\n",
    "\n",
    "# Step 5: Clip negative model predictions\n",
    "def clip_predictions(predictions):\n",
    "    return np.clip(predictions, a_min=0, a_max=None)\n",
    "\n",
    "# Step 6: Prepare and run everything\n",
    "# Check for zero or negative sales in the training data\n",
    "check_for_zero_negative_sales(df_train)\n",
    "\n",
    "# Handle zero or negative sales based on the chosen method (either filter or add_constant)\n",
    "df_train_cleaned = handle_zero_negative_sales(df_train, method='filter')\n",
    "\n",
    "# Prepare feature matrix and target variable for training\n",
    "X_filtered = df_train_cleaned[features]  # Assuming features list is defined earlier\n",
    "y_filtered = df_train_cleaned['sales']\n",
    "\n",
    "# Step 7: Ensure all target values are positive before proceeding\n",
    "try:\n",
    "    if (y_filtered <= 0).any():\n",
    "        raise ValueError(\"Zero or negative values found in the target data!\")\n",
    "\n",
    "    # Print statistics on the target variable\n",
    "    print(f\"Min sales value: {y_filtered.min()}, Max sales value: {y_filtered.max()}\")\n",
    "    \n",
    "    # Perform hyperparameter tuning\n",
    "    perform_hyperparameter_tuning(X_filtered, y_filtered)\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FURTHER IMPROVEMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster column in train data:\n",
      "   store_nbr  cluster\n",
      "0          1       13\n",
      "1          1       13\n",
      "2          1       13\n",
      "3          1       13\n",
      "4          1       13\n",
      "Cluster column in test data:\n",
      "   store_nbr  cluster\n",
      "0          1       13\n",
      "1          1       13\n",
      "2          1       13\n",
      "3          1       13\n",
      "4          1       13\n",
      "New interaction features in train data:\n",
      "   promo_holiday  store_cluster_promo\n",
      "0              0                    0\n",
      "1              0                    0\n",
      "2              0                    0\n",
      "3              0                    0\n",
      "4              0                    0\n",
      "New interaction features in test data:\n",
      "   promo_holiday  store_cluster_promo\n",
      "0              0                    0\n",
      "1              0                    0\n",
      "2              0                   26\n",
      "3              0                  260\n",
      "4              0                    0\n"
     ]
    }
   ],
   "source": [
    "# Drop existing 'cluster' column if it exists\n",
    "if 'cluster' in df_train.columns:\n",
    "    df_train.drop(columns=['cluster'], inplace=True)\n",
    "\n",
    "if 'cluster' in df_test.columns:\n",
    "    df_test.drop(columns=['cluster'], inplace=True)\n",
    "\n",
    "# Now merge the 'cluster' information from df_stores\n",
    "df_train = df_train.merge(df_stores[['store_nbr', 'cluster']], on='store_nbr', how='left')\n",
    "df_test = df_test.merge(df_stores[['store_nbr', 'cluster']], on='store_nbr', how='left')\n",
    "\n",
    "# Check if the cluster is merged correctly\n",
    "print(\"Cluster column in train data:\")\n",
    "print(df_train[['store_nbr', 'cluster']].head())\n",
    "\n",
    "print(\"Cluster column in test data:\")\n",
    "print(df_test[['store_nbr', 'cluster']].head())\n",
    "\n",
    "# Add interaction between promotion and holiday, and promotion and store cluster\n",
    "df_train['promo_holiday'] = df_train['onpromotion'] * df_train['is_holiday']\n",
    "df_train['store_cluster_promo'] = df_train['onpromotion'] * df_train['cluster']\n",
    "\n",
    "df_test['promo_holiday'] = df_test['onpromotion'] * df_test['is_holiday']\n",
    "df_test['store_cluster_promo'] = df_test['onpromotion'] * df_test['cluster']\n",
    "\n",
    "# Check if the new features are added\n",
    "print(\"New interaction features in train data:\")\n",
    "print(df_train[['promo_holiday', 'store_cluster_promo']].head())\n",
    "\n",
    "print(\"New interaction features in test data:\")\n",
    "print(df_test[['promo_holiday', 'store_cluster_promo']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data with lag features:\n",
      "   store_nbr      family  sales  sales_lag_1  sales_lag_7  sales_lag_14\n",
      "0          1  AUTOMOTIVE    0.0          NaN          NaN           NaN\n",
      "1          1   BABY CARE    0.0          NaN          NaN           NaN\n",
      "2          1      BEAUTY    0.0          NaN          NaN           NaN\n",
      "3          1   BEVERAGES    0.0          NaN          NaN           NaN\n",
      "4          1       BOOKS    0.0          NaN          NaN           NaN\n"
     ]
    }
   ],
   "source": [
    "def create_lag_features(df, lags=[1, 7, 14, 30, 60, 90, 180]):\n",
    "    for lag in lags:\n",
    "        df[f'sales_lag_{lag}'] = df.groupby(['store_nbr', 'family'])['sales'].shift(lag)\n",
    "    return df\n",
    "\n",
    "# Apply lag features to the train dataset only\n",
    "df_train = create_lag_features(df_train)\n",
    "\n",
    "# In the test dataset, we won't have 'sales' data for lag features,\n",
    "# so fill missing lag values with 0 or any default value you want.\n",
    "df_test.fillna(0, inplace=True)\n",
    "\n",
    "# Check if the lag features are correctly applied in df_train\n",
    "print(\"Train data with lag features:\")\n",
    "print(df_train[['store_nbr', 'family', 'sales', 'sales_lag_1', 'sales_lag_7', 'sales_lag_14']].head())\n",
    "\n",
    "# If you still want to include lag features in the test set,\n",
    "# you can use forward-fill based on the last available training data\n",
    "# or initialize them with 0 for predictions (depending on your approach)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate days to next holiday and days since last holiday\n",
    "def add_holiday_distance_features(df, holidays_df):\n",
    "    holidays_df['date'] = pd.to_datetime(holidays_df['date'])\n",
    "    holidays_df = holidays_df[holidays_df['transferred'] == False]\n",
    "\n",
    "    # Create a list of unique holiday dates\n",
    "    holiday_dates = holidays_df['date'].unique()\n",
    "\n",
    "    df['days_until_next_holiday'] = df['date'].apply(lambda x: min((holiday_dates - x).days) if x < max(holiday_dates) else 0)\n",
    "    df['days_since_last_holiday'] = df['date'].apply(lambda x: min((x - holiday_dates).days) if x > min(holiday_dates) else 0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the holiday distance features to the train and test datasets\n",
    "df_train = add_holiday_distance_features(df_train, df_holidays)\n",
    "df_test = add_holiday_distance_features(df_test, df_holidays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cyclic features for day of year and day of week\n",
    "df_train['day_of_year_sin'] = np.sin(2 * np.pi * df_train['day_of_year'] / 365)\n",
    "df_train['day_of_year_cos'] = np.cos(2 * np.pi * df_train['day_of_year'] / 365)\n",
    "df_train['day_of_week_sin'] = np.sin(2 * np.pi * df_train['day_of_week'] / 7)\n",
    "df_train['day_of_week_cos'] = np.cos(2 * np.pi * df_train['day_of_week'] / 7)\n",
    "\n",
    "df_test['day_of_year_sin'] = np.sin(2 * np.pi * df_test['day_of_year'] / 365)\n",
    "df_test['day_of_year_cos'] = np.cos(2 * np.pi * df_test['day_of_year'] / 365)\n",
    "df_test['day_of_week_sin'] = np.sin(2 * np.pi * df_test['day_of_week'] / 7)\n",
    "df_test['day_of_week_cos'] = np.cos(2 * np.pi * df_test['day_of_week'] / 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rolling mean and standard deviation features for different window sizes\n",
    "def create_rolling_features(df, windows=[7, 14, 30, 60, 90, 180]):\n",
    "    for window in windows:\n",
    "        df[f'sales_roll_mean_{window}'] = df.groupby(['store_nbr', 'family'])['sales'].transform(lambda x: x.rolling(window).mean())\n",
    "        df[f'sales_roll_std_{window}'] = df.groupby(['store_nbr', 'family'])['sales'].transform(lambda x: x.rolling(window).std())\n",
    "    return df\n",
    "\n",
    "# Apply rolling features to the training data\n",
    "df_train = create_rolling_features(df_train)\n",
    "\n",
    "# Since there are no sales data in the test set, fill missing rolling feature values with 0\n",
    "df_test.fillna(0, inplace=True)\n",
    "\n",
    "# Now define your features, ensuring the new rolling features are included\n",
    "features = ['onpromotion', 'dcoilwtico', 'transactions', 'year', 'month', 'day',\n",
    "            'day_of_week_sin', 'day_of_week_cos', 'day_of_year_sin', 'day_of_year_cos',\n",
    "            'week_of_year', 'time_since_last_promo', 'is_holiday',\n",
    "            'sales_lag_1', 'sales_lag_7', 'sales_lag_14', 'sales_lag_30',\n",
    "            'sales_lag_60', 'sales_lag_90', 'sales_roll_mean_30', 'sales_roll_std_30',\n",
    "            'sales_roll_mean_90', 'sales_roll_std_90', 'sales_roll_mean_180', 'sales_roll_std_180']\n",
    "\n",
    "# Prepare the feature matrix and target variable\n",
    "X = df_train[features]\n",
    "y = df_train['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010712 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4330\n",
      "[LightGBM] [Info] Number of data points in the train set: 501336, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 207.328590\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's rmse: 422.713\n",
      "[200]\tvalid_0's rmse: 290.567\n",
      "[300]\tvalid_0's rmse: 259.988\n",
      "[400]\tvalid_0's rmse: 252.886\n",
      "[500]\tvalid_0's rmse: 250.955\n",
      "[600]\tvalid_0's rmse: 250.403\n",
      "Early stopping, best iteration is:\n",
      "[639]\tvalid_0's rmse: 250.032\n",
      "Validation RMSLE: 1.0184353903444463\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016363 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4494\n",
      "[LightGBM] [Info] Number of data points in the train set: 1002672, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 241.854953\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's rmse: 446.701\n",
      "[200]\tvalid_0's rmse: 275.017\n",
      "[300]\tvalid_0's rmse: 237.156\n",
      "[400]\tvalid_0's rmse: 230.267\n",
      "[500]\tvalid_0's rmse: 230.278\n",
      "Early stopping, best iteration is:\n",
      "[450]\tvalid_0's rmse: 229.732\n",
      "Validation RMSLE: 1.2710941382143968\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024078 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4524\n",
      "[LightGBM] [Info] Number of data points in the train set: 1504008, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 271.076501\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's rmse: 546.86\n",
      "[200]\tvalid_0's rmse: 337.441\n",
      "[300]\tvalid_0's rmse: 281.26\n",
      "[400]\tvalid_0's rmse: 266.686\n",
      "[500]\tvalid_0's rmse: 261.661\n",
      "[600]\tvalid_0's rmse: 259.239\n",
      "[700]\tvalid_0's rmse: 257.937\n",
      "[800]\tvalid_0's rmse: 257.271\n",
      "[900]\tvalid_0's rmse: 256.843\n",
      "[1000]\tvalid_0's rmse: 256.504\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[986]\tvalid_0's rmse: 256.496\n",
      "Validation RMSLE: 0.6811335436498478\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4590\n",
      "[LightGBM] [Info] Number of data points in the train set: 2005344, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 307.524882\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's rmse: 602.754\n",
      "[200]\tvalid_0's rmse: 416.309\n",
      "[300]\tvalid_0's rmse: 377.899\n",
      "[400]\tvalid_0's rmse: 370.793\n",
      "[500]\tvalid_0's rmse: 369.303\n",
      "[600]\tvalid_0's rmse: 368.888\n",
      "Early stopping, best iteration is:\n",
      "[609]\tvalid_0's rmse: 368.831\n",
      "Validation RMSLE: 0.7709394077306774\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052121 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2506680, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 332.722695\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's rmse: 611.033\n",
      "[200]\tvalid_0's rmse: 366.42\n",
      "[300]\tvalid_0's rmse: 303.004\n",
      "[400]\tvalid_0's rmse: 285.705\n",
      "[500]\tvalid_0's rmse: 279.441\n",
      "[600]\tvalid_0's rmse: 275.823\n",
      "[700]\tvalid_0's rmse: 273.562\n",
      "[800]\tvalid_0's rmse: 272.525\n",
      "[900]\tvalid_0's rmse: 271.637\n",
      "[1000]\tvalid_0's rmse: 270.785\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 270.785\n",
      "Validation RMSLE: 0.6627225449749802\n",
      "Average RMSLE across all splits: 0.8808650049828696\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Use TimeSeriesSplit for cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Initialize lists to store evaluation results\n",
    "rmsle_list = []\n",
    "\n",
    "# Loop through each split in the cross-validation\n",
    "for train_index, val_index in tscv.split(X):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    \n",
    "    # Create LightGBM dataset\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val)\n",
    "    \n",
    "    # Set LightGBM parameters\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',  # We will calculate RMSLE manually\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate': 0.01,\n",
    "        'num_leaves': 50,\n",
    "        'max_depth': -1,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 1,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    # Use callbacks for early stopping and logging\n",
    "    callbacks = [\n",
    "        lgb.early_stopping(stopping_rounds=50),\n",
    "        lgb.log_evaluation(period=100)\n",
    "    ]\n",
    "    \n",
    "    # Train the model with early stopping\n",
    "    model = lgb.train(params, train_data, valid_sets=[val_data], num_boost_round=1000, callbacks=callbacks)\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    y_val_pred = np.clip(y_val_pred, a_min=0, a_max=None)  # Ensure no negative predictions\n",
    "    \n",
    "    # Calculate RMSLE on validation set\n",
    "    rmsle = np.sqrt(mean_squared_log_error(y_val, y_val_pred))\n",
    "    rmsle_list.append(rmsle)\n",
    "    \n",
    "    print(f\"Validation RMSLE: {rmsle}\")\n",
    "\n",
    "# Average RMSLE across all splits\n",
    "avg_rmsle = np.mean(rmsle_list)\n",
    "print(f\"Average RMSLE across all splits: {avg_rmsle}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering: Seasonality and Interaction Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Cyclic features for day of week and day of year\n",
    "def add_cyclic_features(df):\n",
    "    df['day_of_week_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "    df['day_of_week_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "    \n",
    "    df['day_of_year_sin'] = np.sin(2 * np.pi * df['day_of_year'] / 365)\n",
    "    df['day_of_year_cos'] = np.cos(2 * np.pi * df['day_of_year'] / 365)\n",
    "    return df\n",
    "\n",
    "# Apply to both train and test datasets\n",
    "df_train = add_cyclic_features(df_train)\n",
    "df_test = add_cyclic_features(df_test)\n",
    "\n",
    "# Add interaction between promotion and holiday, and promotion and store cluster\n",
    "df_train['promo_holiday'] = df_train['onpromotion'] * df_train['is_holiday']\n",
    "df_train['store_cluster_promo'] = df_train['onpromotion'] * df_train['cluster']\n",
    "\n",
    "df_test['promo_holiday'] = df_test['onpromotion'] * df_test['is_holiday']\n",
    "df_test['store_cluster_promo'] = df_test['onpromotion'] * df_test['cluster']\n",
    "\n",
    "# Updated feature list to include cyclic and interaction features\n",
    "features = ['onpromotion', 'dcoilwtico', 'transactions', 'year', 'month', 'day', \n",
    "            'day_of_week_sin', 'day_of_week_cos', 'day_of_year_sin', 'day_of_year_cos',\n",
    "            'week_of_year', 'time_since_last_promo', 'is_holiday', \n",
    "            'sales_lag_1', 'sales_lag_7', 'sales_lag_14', 'sales_lag_30', \n",
    "            'sales_lag_60', 'sales_lag_90',\n",
    "            'promo_holiday', 'store_cluster_promo']\n",
    "\n",
    "# Prepare the feature matrix and target variable\n",
    "X = df_train[features]\n",
    "y = df_train['sales']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization Tuning: Fine-tune L1 and L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2800\n",
      "[LightGBM] [Info] Number of data points in the train set: 501336, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 207.328590\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's rmse: 426.396\n",
      "[200]\tvalid_0's rmse: 296.707\n",
      "[300]\tvalid_0's rmse: 266.716\n",
      "[400]\tvalid_0's rmse: 257.897\n",
      "[500]\tvalid_0's rmse: 254.907\n",
      "[600]\tvalid_0's rmse: 253.214\n",
      "[700]\tvalid_0's rmse: 252.076\n",
      "[800]\tvalid_0's rmse: 251.307\n",
      "[900]\tvalid_0's rmse: 250.75\n",
      "[1000]\tvalid_0's rmse: 250.368\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[981]\tvalid_0's rmse: 250.346\n",
      "Validation RMSLE: 0.8912228132695358\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018473 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3115\n",
      "[LightGBM] [Info] Number of data points in the train set: 1002672, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 241.854953\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's rmse: 440.271\n",
      "[200]\tvalid_0's rmse: 269.639\n",
      "[300]\tvalid_0's rmse: 235.966\n",
      "[400]\tvalid_0's rmse: 232.07\n",
      "Early stopping, best iteration is:\n",
      "[435]\tvalid_0's rmse: 231.885\n",
      "Validation RMSLE: 1.2250898726242359\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024775 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3302\n",
      "[LightGBM] [Info] Number of data points in the train set: 1504008, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 271.076501\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's rmse: 538.102\n",
      "[200]\tvalid_0's rmse: 331.829\n",
      "[300]\tvalid_0's rmse: 281.996\n",
      "[400]\tvalid_0's rmse: 270.05\n",
      "[500]\tvalid_0's rmse: 267.063\n",
      "[600]\tvalid_0's rmse: 265.9\n",
      "[700]\tvalid_0's rmse: 265.338\n",
      "[800]\tvalid_0's rmse: 264.818\n",
      "Early stopping, best iteration is:\n",
      "[826]\tvalid_0's rmse: 264.642\n",
      "Validation RMSLE: 0.5993772566935448\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033490 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3369\n",
      "[LightGBM] [Info] Number of data points in the train set: 2005344, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 307.524882\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's rmse: 593.068\n",
      "[200]\tvalid_0's rmse: 408.659\n",
      "[300]\tvalid_0's rmse: 373.97\n",
      "[400]\tvalid_0's rmse: 369.343\n",
      "[500]\tvalid_0's rmse: 368.981\n",
      "Early stopping, best iteration is:\n",
      "[533]\tvalid_0's rmse: 368.923\n",
      "Validation RMSLE: 0.784655528141152\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3458\n",
      "[LightGBM] [Info] Number of data points in the train set: 2506680, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 332.722695\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's rmse: 604.27\n",
      "[200]\tvalid_0's rmse: 358.625\n",
      "[300]\tvalid_0's rmse: 295.652\n",
      "[400]\tvalid_0's rmse: 279.894\n",
      "[500]\tvalid_0's rmse: 274.562\n",
      "[600]\tvalid_0's rmse: 272.422\n",
      "[700]\tvalid_0's rmse: 271.176\n",
      "[800]\tvalid_0's rmse: 270.459\n",
      "[900]\tvalid_0's rmse: 270.105\n",
      "[1000]\tvalid_0's rmse: 269.851\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[996]\tvalid_0's rmse: 269.84\n",
      "Validation RMSLE: 0.5777462345781641\n",
      "Average RMSLE across all splits: 0.8156183410613265\n"
     ]
    }
   ],
   "source": [
    "# Set LightGBM parameters with fine-tuned regularization\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.01,\n",
    "    'num_leaves': 200,  # Adjusted based on previous tuning\n",
    "    'min_data_in_leaf': 50,  # Regularization tuning\n",
    "    'lambda_l1': 0.1,  # L1 regularization\n",
    "    'lambda_l2': 1,    # L2 regularization\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# Train the model using TimeSeriesSplit and LightGBM\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "rmsle_list = []\n",
    "\n",
    "for train_index, val_index in tscv.split(X):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "    callbacks = [\n",
    "        lgb.early_stopping(stopping_rounds=50),\n",
    "        lgb.log_evaluation(period=100)\n",
    "    ]\n",
    "\n",
    "    model = lgb.train(params, train_data, valid_sets=[val_data], num_boost_round=1000, callbacks=callbacks)\n",
    "\n",
    "    # Predictions and RMSLE Calculation\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    y_val_pred = np.clip(y_val_pred, a_min=0, a_max=None)  # Clip negative predictions\n",
    "\n",
    "    rmsle = np.sqrt(mean_squared_log_error(y_val, y_val_pred))\n",
    "    rmsle_list.append(rmsle)\n",
    "    print(f\"Validation RMSLE: {rmsle}\")\n",
    "\n",
    "# Average RMSLE across all splits\n",
    "avg_rmsle = np.mean(rmsle_list)\n",
    "print(f\"Average RMSLE across all splits: {avg_rmsle}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
